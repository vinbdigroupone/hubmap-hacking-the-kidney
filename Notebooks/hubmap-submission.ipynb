{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Description\nThis kernel provides a starter Pytorch code for inference that performs dividing the images into tiles([based on this kernel](https://www.kaggle.com/iafoss/256x256-images)), selection of tiles with tissue, evaluation of the predictions of multiple models with TTA, combining the tile masks back into image level masks, and conversion into RLE. The inference is performed based on models trained in the [fast.ai starter kernel](https://www.kaggle.com/iafoss/hubmap-fast-ai-starter), provided by me. I hope it will help you to get started with this competition."},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p /tmp/pip/cache/\n!cp ../input/segmentationmodelspytorch/segmentation_models/efficientnet_pytorch-0.6.3.xyz /tmp/pip/cache/efficientnet_pytorch-0.6.3.tar.gz\n!cp ../input/segmentationmodelspytorch/segmentation_models/pretrainedmodels-0.7.4.xyz /tmp/pip/cache/pretrainedmodels-0.7.4.tar.gz\n!cp ../input/segmentationmodelspytorch/segmentation_models/segmentation-models-pytorch-0.1.2.xyz /tmp/pip/cache/segmentation_models_pytorch-0.1.2.tar.gz\n!cp ../input/segmentationmodelspytorch/segmentation_models/timm-0.1.20-py3-none-any.whl /tmp/pip/cache/\n!cp ../input/segmentationmodelspytorch/segmentation_models/timm-0.2.1-py3-none-any.whl /tmp/pip/cache/\n!pip install --no-index --find-links /tmp/pip/cache/ efficientnet-pytorch\n!pip install --no-index --find-links /tmp/pip/cache/ segmentation-models-pytorch\n!mkdir -p /root/.cache/torch/hub/checkpoints/\n!cp ../input/pytorch-pretrained-models/se_resnext50_32x4d-a260b3a4.pth /root/.cache/torch/hub/checkpoints/\n!cp ../input/pytorch-pretrained-models/resnet34-333f7ec4.pth /root/.cache/torch/hub/checkpoints/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport tifffile as tiff\nimport cv2\nimport os\nimport gc\nfrom tqdm.notebook import tqdm\n\nfrom fastai.vision.all import *\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport segmentation_models_pytorch as smp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sz = 256   #the size of tiles\nreduce = 4 #reduce the original images by 4 times\n# TH = 0.39  #threshold for positive predictions\nTH = 0.59  #threshold for positive predictions\n\nDATA = '../input/hubmap-kidney-segmentation/test/'\nMODELS = [f'../input/hubmap-fast-ai-starter/model_{i}.pth' for i in range(4)]\ndf_sample = pd.read_csv('../input/hubmap-kidney-segmentation/sample_submission.csv')\nbs = 64\nNUM_WORKERS = 2\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#functions to convert encoding to mask and mask to encoding\ndef enc2mask(encs, shape):\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for m,enc in enumerate(encs):\n        if isinstance(enc,np.float) and np.isnan(enc): continue\n        s = enc.split()\n        for i in range(len(s)//2):\n            start = int(s[2*i]) - 1\n            length = int(s[2*i+1])\n            img[start:start+length] = 1 + m\n    return img.reshape(shape).T\n\ndef mask2enc(mask, n=1):\n    pixels = mask.T.flatten()\n    encs = []\n    for i in range(1,n+1):\n        p = (pixels == i).astype(np.int8)\n        if p.sum() == 0: encs.append(np.nan)\n        else:\n            p = np.concatenate([[0], p, [0]])\n            runs = np.where(p[1:] != p[:-1])[0] + 1\n            runs[1::2] -= runs[::2]\n            encs.append(' '.join(str(x) for x in runs))\n    return encs\n\n#https://www.kaggle.com/bguberfain/memory-aware-rle-encoding\n#with bug fix\ndef rle_encode_less_memory(img):\n    #watch out for the bug\n    pixels = img.T.flatten()\n    \n    # This simplified method requires first and last pixel to be zero\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] -= runs[::2]\n    \n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/iafoss/256x256-images\nmean = np.array([0.65459856,0.48386562,0.69428385])\nstd = np.array([0.15167958,0.23584107,0.13146145])\n\ndef img2tensor(img,dtype:np.dtype=np.float32):\n    if img.ndim==2 : img = np.expand_dims(img,2)\n    img = np.transpose(img,(2,0,1))\n    return torch.from_numpy(img.astype(dtype, copy=False))\n\nclass HuBMAPTestDataset(Dataset):\n    def __init__(self, imgs, idxs):\n        self.imgs = imgs\n        self.fnames = idxs\n        \n    def __len__(self):\n        return len(self.fnames)\n    \n    def __getitem__(self, idx):\n        return img2tensor((self.imgs[idx]/255.0 - mean)/std)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport glob\n\nimport torch\nfrom torch.nn import Sigmoid\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom IPython.display import clear_output\n\nfrom sklearn.model_selection import KFold\n\nimport matplotlib.pyplot as plt\n\nimport albumentations as A","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Unet(encoder_backbone='resnet18', encoder_weights='imagenet'):\n    return smp.Unet(encoder_name=encoder_backbone,\n                    encoder_weights=encoder_weights,\n                    in_channels=3,\n                    classes=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1 = Unet('se_resnext50_32x4d')\nmodel_path_1 = '../input/resnext50-2/best_model (4).pth'\nmodel_3 = Unet('resnet34')\nmodel_path_3 = '../input/resnet34-unet-lovazs-loss/best_model_resnet34_lovazsloss.pth'\n\nmodel_1.load_state_dict(torch.load(model_path_1))\nmodel_3.load_state_dict(torch.load(model_path_3))\n\nmodel_1.to('cuda')\nmodel_3.to('cuda')\n\nmodels = []\nmodels.append(model_1)\nmodels.append(model_3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"#iterator like wrapper that returns predicted masks\nclass Model_pred:\n    def __init__(self, models, dl, tta:bool=True, half:bool=False):\n        self.models = models\n        self.dl = dl\n        self.tta = tta\n        self.half = half\n        \n    def __iter__(self):\n        count=0\n        with torch.no_grad():\n            for x in iter(self.dl):\n                x = x.to(device)\n                if self.half: x = x.half()\n                py = None\n                # predict without tta for all models, then add them up\n                for model in self.models:\n                    p = model(x)\n                    p = torch.sigmoid(p).detach()\n                    if py is None: py = p\n                    else: py += p\n                if self.tta:\n                    #x,y,xy flips as TTA\n                    flips = [[-1],[-2],[-2,-1]]\n                    for f in flips:\n                        xf = torch.flip(x,f)\n                        for model in self.models:\n                            p = model(xf)\n                            p = torch.flip(p,f)\n                            py += torch.sigmoid(p).detach()\n                    py /= (1+len(flips))        \n                py /= len(self.models)\n                    \n                py = F.upsample(py, scale_factor=reduce, mode=\"bilinear\")\n                py = py.permute(0,2,3,1).float().cpu()\n                batch_size = len(py)\n                for i in range(batch_size):\n                    yield py[i]\n                    count += 1\n                    \n    def __len__(self):\n        return len(self.dl.dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Somehow I cannot resolve the submission error with consideration of the\n#private LB data, and the submission error doesn't give an informative\n#output. So, for now I share the notbook that makes a submission only\n#to the public LB, and later I'll try to resolve the issue.\n#IMPORTANT: This notebook doesn't perform predictions for the private LB.\nnames,preds = [],[]\nsamples = ['b9a3865fc','b2dc8411c','26dc41664','c68fe75ea','afa5e8098']\nsamples_n = [id for id in df_sample.id if id not in samples]\n\nnames += samples_n\npreds += [np.NaN]*len(samples_n)\ndf_sample = df_sample.loc[df_sample.id.isin(samples)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s_th = 40  #saturation blancking threshold\np_th = 200*sz//256 #threshold for the minimum number of pixels\n#names,preds = [],[]\nfor idx,row in tqdm(df_sample.iterrows(),total=len(df_sample)):\n    idx = row['id']\n    #read image\n    img = tiff.imread(os.path.join(DATA,idx+'.tiff'))\n    if len(img.shape) == 5: img = np.transpose(img.squeeze(), (1,2,0))\n    \n    #add padding to make the image dividable into tiles\n    img_shape = img.shape\n    pad0 = (reduce*sz - img_shape[0]%(reduce*sz))%(reduce*sz)\n    pad1 = (reduce*sz - img_shape[1]%(reduce*sz))%(reduce*sz)\n    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],\n                 constant_values=0)\n\n    #split image into tiles using the reshape+transpose trick\n    if reduce != 1:\n        img = cv2.resize(img,(img.shape[1]//reduce,img.shape[0]//reduce),\n                     interpolation = cv2.INTER_AREA)\n    img_shape_p = img.shape\n    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n\n    #select tiles for running the model\n    imgs,idxs = [],[]\n    for i,im in enumerate(img):\n        #remove black or gray images based on saturation check\n        hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n        h, s, v = cv2.split(hsv)\n        if (s>s_th).sum() <= p_th or im.sum() <= p_th: continue\n        imgs.append(im)\n        idxs.append(i)\n    #tile dataset\n    ds = HuBMAPTestDataset(imgs,idxs)\n    dl = DataLoader(ds,bs,num_workers=NUM_WORKERS,shuffle=False,pin_memory=True)\n    mp = Model_pred(models,dl)\n    \n    #generate masks\n    mask = torch.zeros(img.shape[0],sz*reduce,sz*reduce,dtype=torch.int8)\n    for i,p in zip(idxs,iter(mp)): mask[i] = p.squeeze(-1) > TH\n    \n    #reshape tiled masks into a single mask and crop padding\n    mask = mask.view(img_shape_p[0]//sz,img_shape_p[1]//sz,sz*reduce,sz*reduce).\\\n        permute(0,2,1,3).reshape(img_shape_p[0]*reduce,img_shape_p[1]*reduce)\n    mask = mask[pad0//2:-(pad0-pad0//2) if pad0 > 0 else img_shape_p[0]*reduce,\n        pad1//2:-(pad1-pad1//2) if pad1 > 0 else img_shape_p[1]*reduce]\n    \n    #convert to rle\n    #https://www.kaggle.com/bguberfain/memory-aware-rle-encoding\n    rle = rle_encode_less_memory(mask.numpy())\n    names.append(idx)\n    preds.append(rle)\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'id':names,'predicted':preds})\ndf.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}